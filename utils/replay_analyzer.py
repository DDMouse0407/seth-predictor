import streamlit as st
import requests
import pandas as pd
from datetime import datetime
from bs4 import BeautifulSoup
import joblib
import numpy as np
import re
import os

from replay_utils import analyze_replay_url

st.set_page_config(page_title="è³½ç‰¹åˆ†æç³»çµ± - è‡ªå‹•åºè™Ÿå·¥å…·", layout="centered")
st.title("ğŸ”‘ è³½ç‰¹åºè™Ÿè‡ªå‹•åˆ†æå·¥å…· v2.6")
st.markdown("è«‹è¼¸å…¥æ¯æ—¥åºè™Ÿèˆ‡å¸³è™Ÿè³‡è¨Šï¼Œç³»çµ±å°‡è‡ªå‹•é€å‡ºåˆ†æè«‹æ±‚ã€æ“·å–çˆ†é‡‘åœ–ç‰‡èˆ‡å½±ç‰‡å›æ”¾ç¶²å€ï¼Œçµåˆ AI é æ¸¬èˆ‡ä¸‹æ³¨å»ºè­°ï¼Œä¸¦æŒçºŒè¨˜éŒ„å¼·åŒ–å­¸ç¿’ã€‚")

@st.cache_resource
def load_model():
    try:
        return joblib.load("xgb_burst_predictor.pkl")
    except:
        return None

def save_daily_training_data(record):
    file = "daily_training_log.csv"
    df = pd.DataFrame([record])
    if os.path.exists(file):
        df.to_csv(file, mode="a", header=False, index=False)
    else:
        df.to_csv(file, index=False)

def make_betting_decision(prob, threshold=0.6):
    if prob >= threshold:
        return f"âœ… å»ºè­°ä¸‹æ³¨ï¼ˆä¿¡å¿ƒå€¼ {prob*100:.1f}%ï¼‰"
    else:
        return f"â›” å»ºè­°è§€æœ›ï¼ˆä¿¡å¿ƒå€¼ {prob*100:.1f}%ï¼‰"

model = load_model()

with st.form("serial_form"):
    serial = st.text_input("ä»Šæ—¥åºè™Ÿ", placeholder="ä¾‹å¦‚ï¼š115511")
    account = st.text_input("æœƒå“¡å¸³è™Ÿ", placeholder="ä¾‹å¦‚ï¼šmoneymm258")
    amount = st.text_input("è¨­å®šé‡‘é¡", value="1000")
    table = st.text_input("æ¡Œè™Ÿ", value="109")
    device = st.selectbox("è£ç½®é¡å‹", ["ios", "android", "pc"])
    game = st.selectbox("é¸æ“‡éŠæˆ²", ["ATG-è³½ç‰¹", "ATG-å…¶ä»–"])
    submitted = st.form_submit_button("ğŸš€ é–‹å§‹åˆ†æ")

if submitted:
    with st.spinner("æ­£åœ¨æäº¤åºè™Ÿä¸¦æ“·å–åˆ†æçµæœ..."):
        payload = {
            "serial": serial,
            "device": device,
            "account": account,
            "amount": amount,
            "game": game,
            "table": table
        }
        try:
            res = requests.post("https://haoting.info/verifySerial.php", data=payload)
            if res.status_code == 200:
                soup = BeautifulSoup(res.text, "html.parser")
                icons = soup.find_all("img")
                links = soup.find_all("a", href=True)

                results = []
                level_map = {
                    "ç„¡çˆ†ç™¼": 0,
                    "Big Win": 1,
                    "Super Win": 2,
                    "Mega Win": 3,
                    "Ultra Win": 4,
                    "Legendary Win": 5,
                }

                for icon in icons:
                    src = icon.get("src")
                    if src:
                        if "legendary" in src.lower():
                            win_type = "Legendary Win"
                        elif "ultra" in src.lower():
                            win_type = "Ultra Win"
                        elif "mega" in src.lower():
                            win_type = "Mega Win"
                        elif "super" in src.lower():
                            win_type = "Super Win"
                        elif "big" in src.lower():
                            win_type = "Big Win"
                        else:
                            win_type = "ç„¡çˆ†ç™¼"

                        results.append({
                            "æ™‚é–“": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                            "çˆ†ç™¼ç­‰ç´š": win_type,
                            "åœ–ç‰‡": src,
                            "æ•¸å€¼": level_map.get(win_type, 0)
                        })

                replay_urls = []
                for a in links:
                    href = a["href"]
                    if "godeebxp.com/egames" in href and "egyptian-mythology" in href:
                        replay_urls.append(href)

                if results:
                    df = pd.DataFrame(results)
                    st.success("ğŸ‰ çˆ†é‡‘è³‡æ–™æ“·å–æˆåŠŸï¼")
                    st.dataframe(df)
                    csv = df.to_csv(index=False).encode("utf-8")
                    st.download_button("ğŸ“¥ ä¸‹è¼‰çµæœ CSV", data=csv, file_name="haoting_data.csv", mime="text/csv")

                    if model:
                        X_input = np.array(df["æ•¸å€¼"].tail(5)).reshape(1, -1)
                        if X_input.shape[1] < 5:
                            X_input = np.pad(X_input, ((0,0),(5-X_input.shape[1],0)))
                        pred = model.predict_proba(X_input)[0][1]
                        decision = make_betting_decision(pred)

                        st.markdown(f"### ğŸ¤– AI é æ¸¬ä¸‹ä¸€å±€çˆ†é‡‘æ©Ÿç‡ï¼š**{pred*100:.2f}%**")
                        st.markdown(f"### ğŸ’° è‡ªå‹•ä¸‹æ³¨å»ºè­°ï¼š{decision}")

                        save_daily_training_data({
                            "æ—¥æœŸæ™‚é–“": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                            "åºè™Ÿ": serial,
                            "å¸³è™Ÿ": account,
                            "çˆ†ç™¼åˆ†æ•¸é™£åˆ—": df["æ•¸å€¼"].tolist(),
                            "çˆ†é‡‘æ©Ÿç‡": round(pred, 4),
                            "ä¸‹æ³¨å»ºè­°": decision
                        })
                    else:
                        st.warning("å°šæœªè¼‰å…¥ AI æ¨¡å‹ï¼Œè«‹ç¢ºèª xgb_burst_predictor.pkl å­˜åœ¨æ–¼ç›®éŒ„ä¸­ã€‚")
                else:
                    st.warning("æœªåµæ¸¬åˆ°çˆ†é‡‘è³‡è¨Šåœ–ç‰‡ï¼Œå¯èƒ½æœ¬æ¬¡ç„¡çˆ†ç™¼ç­‰ç´šè³‡æ–™ã€‚")

                if replay_urls:
                    st.markdown("---")
                    st.markdown("### ğŸï¸ åµæ¸¬åˆ°å›æ”¾ç¶²å€ï¼š")
                    for url in replay_urls:
                        label = analyze_replay_url(url)
                        st.write(f"{url} ğŸ‘‰ åˆ†æçµæœï¼š**{label}**")

            else:
                st.error(f"åˆ†æå¤±æ•—ï¼Œç‹€æ…‹ç¢¼ï¼š{res.status_code}")
        except Exception as e:
            st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
